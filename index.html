<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="howgtd">










<meta name="description" content="怎么更高效的把事情做好">
<meta name="keywords" content="gtd">
<meta property="og:type" content="website">
<meta property="og:title" content="HowGTD">
<meta property="og:url" content="http://howgtd.com/index.html">
<meta property="og:site_name" content="HowGTD">
<meta property="og:description" content="怎么更高效的把事情做好">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HowGTD">
<meta name="twitter:description" content="怎么更高效的把事情做好">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://howgtd.com/">





  <title>HowGTD</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HowGTD</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Getting Things Done</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://howgtd.com/2019/02/21/sitelist/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="靑枫">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HowGTD">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/21/sitelist/" itemprop="url">sitelist</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-21T21:50:55+08:00">
                2019-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>一，国内咨询机构网站数据报告列表</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=http%3A//report.iresearch.cn/" target="_blank" rel="noopener">艾瑞研究-艾瑞网</a>（互联网行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//index.iresearch.com.cn/app" target="_blank" rel="noopener">艾瑞APP指数</a>-艾瑞网（移动App TOP 1000 月度活跃和日活跃）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//index.iresearch.com.cn/pc" target="_blank" rel="noopener">艾瑞PC指数</a>-艾瑞网（PC TOP 1000-月度活跃和日活跃）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.199it.com/" target="_blank" rel="noopener">199IT互联网数据中心</a>-所有行业报告，内容繁多，支持搜索</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.cnnic.net.cn/hlwfzyj/hlwxzbg/" target="_blank" rel="noopener">中国互联网络信息中心</a>-CNNIC数据可以当做互联网人口普查基础表来看</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.eguan.cn/zhuanti/more.php%3Fcid%3D2884" target="_blank" rel="noopener">http://www.eguan.cn/zhuanti/more.php?cid=2884</a>（易观智库）-仅参考</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.umeng.com/reports.html%3Fspm%3D0.0.0.0.eIY17Q%26from%3Dhp" target="_blank" rel="noopener">【友盟+】数据报告</a>-（被阿里收购）仅参考</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.dcci.com.cn/report/index.html" target="_blank" rel="noopener">http://www.dcci.com.cn/report/index.html</a>（DCCI）-仅参考</li>
<li><a href="https://link.zhihu.com/?target=http%3A//cn.sino-mr.com/viewpoint" target="_blank" rel="noopener">北京赛诺市场研究有限责任公司</a>赛诺数据，智能机出货量的专业统计</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.catr.cn/kxyj/qwfb/qwsj/" target="_blank" rel="noopener">中国信通院-研究成果-权威发布-权威数据</a>国家智能机出货量的官方统计</li>
<li><a href="https://link.zhihu.com/?target=http%3A//mi.talkingdata.com/reports.html%3Fcategory%3Dall" target="_blank" rel="noopener">数据报告-移动观象台-TalkingData</a>（Talkingdata报告）-行业报告可看</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.iimedia.cn/%23shuju" target="_blank" rel="noopener">艾媒网-全球移动互联网行业数据发布平台/iiMedia Research出品</a>-行业报告可看</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.dataeye.com/report.html" target="_blank" rel="noopener">https://www.dataeye.com/report.html</a>-dataeye-偏手游方向</li>
<li><a href="https://link.zhihu.com/?target=http%3A//aso100.com/" target="_blank" rel="noopener">ASO100 - 专业App Store数据平台丨ASO优化专家平台丨iOS榜单排行榜查询工具</a> </li>
<li>电影电视行业<a href="https://link.zhihu.com/?target=http%3A//www.entgroup.cn/report/f/" target="_blank" rel="noopener">免费报告列表页</a>-艺恩咨询（是个研究娱乐行业的公司，提供行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.dotour.cn/topics/data" target="_blank" rel="noopener">旅游数据报告-旅游圈</a>（旅游行业报告）</li>
</ol>
<p>排名不分先后</p>
<p><strong>二，国内互联网公司数据报告网站列表</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=http%3A//djt.qq.com/ppts/" target="_blank" rel="noopener">讲座PPT-腾讯大讲堂</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.tencent.com/zh-cn/ir/reports.shtml" target="_blank" rel="noopener">Tencent 腾讯</a>-业绩报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//mta.qq.com/mta/operation/" target="_blank" rel="noopener">腾讯大数据</a>-腾讯云数据分析出来的行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//developer.baidu.com/report%3Ftype%3Dinvestigate" target="_blank" rel="noopener">百度开放服务平台</a>-百度云数据分析出来的行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//data.baidu.com/" target="_blank" rel="noopener">百度数据研究中心 提供行业研究报告、行业分析报告</a>-百度数据中心报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.aliresearch.com/" target="_blank" rel="noopener">首页-阿里研究院</a>-阿里行业研究报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//mxd.tencent.com/" target="_blank" rel="noopener">腾讯MXD移动互联网设计中心</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//ecd.tencent.com/" target="_blank" rel="noopener">https://isux.tencent.com/category/ur</a> -腾讯交互设计报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//ued.taobao.org/blog/category/bowen/user-research/" target="_blank" rel="noopener">用户研究 | TaoBaoUED</a>-淘宝UED用户研究报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//uedc.163.com/" target="_blank" rel="noopener">网易用户体验设计中心</a>-网易UED用户研究报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//c.youku.com/ykvr/index" target="_blank" rel="noopener">网络视频数据报告</a>-优酷指数行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.pptv.com/aboutus/download/" target="_blank" rel="noopener">PP指数_PPTV聚力</a>-PPTV指数行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//tech.91.com/industry-list/industryreport/" target="_blank" rel="noopener">手机行业报告_提供安卓、苹果等智能手机行业报告_91手机资讯-</a>-91行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//zt.360.cn/report/" target="_blank" rel="noopener">360研究报告_360安全中心</a>-360应用商店等产品出品报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//tech.qq.com/biznext/list.html" target="_blank" rel="noopener">企鹅智酷_腾讯网</a>-腾讯出品行业报告</li>
</ol>
<p>排名不分先后</p>
<p><strong>三，国外咨询机构网站数据报告列表（国外咨询机构较多，数据详实，无论是海外出海产品，海外报告中多有亚洲和中国的重点研究，相关报告和趋势分析都可以选看）</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=http%3A//www.flurry.com/" target="_blank" rel="noopener">Flurry</a>-国外app行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//cn.blog.appannie.com/" target="_blank" rel="noopener">App Annie Blog</a>-app指数报告</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.appannie.com/insights/" target="_blank" rel="noopener">https://www.appannie.com/insights/</a> (Appnnie的行业包括，包括app 分发行业的分发量和收入）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//intelligence.businessinsider.com/" target="_blank" rel="noopener">BI Intelligence</a>-business insider的报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.emarketer.com/Articles" target="_blank" rel="noopener">Today’s Articles on Digital Marketing and Media</a>-emarker的报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.newzoo.com/category/press-releases/" target="_blank" rel="noopener">http://www.newzoo.com/category/press-releases/</a>-newzoo侧重于手游行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.gartner.com/newsroom/archive/" target="_blank" rel="noopener">Gartner Press Release Archives</a>-gartner侧重于硬件的出货量，包括智能机和PC等</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.idc.com/search/geography/perform_.do%3Fpage%3D1%26hitsPerPage%3D25%26sortBy%3DRELEVANCY%26lang%3DEnglish%26srchIn%3DALLRESEARCH%26src%3D%26athrT%3D10%26geo%3D3_332%26cmpT%3D10%26pgT%3D10%26_xpn%3Dfalse" target="_blank" rel="noopener">IDC - Search Results</a>-IDC的硬件出货量全球报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.yozzo.com/news-and-information" target="_blank" rel="noopener">Yozzo Telecom News</a> </li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.jpmorgan.com/pages/jpmorgan" target="_blank" rel="noopener">J.P. Morgan Home</a>-摩根投行报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.tohmatsu.com/view/en_JP/jp" target="_blank" rel="noopener">德勤中国 | 审计, 企业管理咨询, 财务咨询, 风险管理, 税务服务及行业洞察</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.comscore.com/" target="_blank" rel="noopener">Precisely Everywhere</a>-comscore的互联网行业报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.ericsson.com/" target="_blank" rel="noopener">Ericsson - A world of communication</a>（Global移动行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.gamesindustry.biz/" target="_blank" rel="noopener">GamesIndustry.biz</a>（Global游戏行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//adfonic.com/" target="_blank" rel="noopener">http://adfonic.com/</a>（Global广告行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.canalys.com/" target="_blank" rel="noopener">Canalys | Insight. Innovation. Impact.</a>（Global智能机报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.juniperresearch.com/" target="_blank" rel="noopener">Mobile, Online &amp; Digital Market Research, Data &amp; Consultancy</a>（通信无线报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.gfk.com/Pages/default.aspx" target="_blank" rel="noopener">Home | GfK Global</a>（终端比较专业的报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.kantarworldpanel.com/global" target="_blank" rel="noopener">Kantar Worldpanel</a>（主要统计Android和ios的市场份额）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.pwc.com/us/en/publications.html" target="_blank" rel="noopener">PwC publications</a>（皮尤的所有用户，市场研究报告）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.fiksu.com/" target="_blank" rel="noopener">Fiksu | Data-fueled mobile marketing</a>（统计app用户获取成本和应用商店下载频次的监测）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.weforum.org/reports" target="_blank" rel="noopener">https://www.weforum.org/reports</a>（世界经济论坛的报告，揭示国内外发展的大趋势）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//blog.jampp.com/insights/" target="_blank" rel="noopener">Insights - Jampp</a> （Jampp是国外的app 的粘性和转化漏洞的网站，在insights里还有行业的app的retention等benchmark的数据，有些类似flurry的行业数据）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.rolandberger.com.cn/publications/publications_in_Greater_China/industry_reports/index.html" target="_blank" rel="noopener">罗兰贝格行业评论</a> 战略和行业评论和报告</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.pwccn.com/home/chi/libraryindex_chi.html" target="_blank" rel="noopener">普华永道: </a>blog  各个行业的主要发现和行业报告</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.similarweb.com/" target="_blank" rel="noopener">Website Traffic &amp; Mobile App Analytics</a> （similar web 以色列的网站分析工具，可以分析任何网站，包括用户，来源，终端，分布等等，数据非常棒）</li>
</ol>
<p>排名不分先后</p>
<p><strong>四，各大公司不定期发布的报告，比如（细分方向的时候用）</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=http%3A//www.askci.com/news/chanye/2016/01/20/101053mz1i.shtml" target="_blank" rel="noopener">高德地图：2015年度中国主要城市交通分析报告</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//tech.qq.com/a/20151216/047691.htm" target="_blank" rel="noopener">微信城市服务发布《2015微信政务民生白皮书》</a> </li>
<li><a href="https://link.zhihu.com/?target=http%3A//socialbeta.com/t/report-taobao-consumption-trends-data" target="_blank" rel="noopener">【报告】淘宝发布 2015 中国消费趋势数据，2015 年我们为什么买单？</a> </li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.growingio.com/posts/hu-lian-wang-chuang-ye-gong-si-yong-hu-zeng-zhang-shi-zhan-mi-ji" target="_blank" rel="noopener">互联网增长的第一本数据分析手册</a>-Growing IO的公开手册</li>
<li><a href="https://link.zhihu.com/?target=http%3A//blog.talkingdata.net/%3Fp%3D221" target="_blank" rel="noopener">移动游戏运营数据分析指标白皮书（一）</a>-Talkingdata 运营指标分析白皮书</li>
</ol>
<p>排名不分先后<br>（不局限于以上list）</p>
<p><strong>五，企业信息报告</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=http%3A//www.chinaipo.com/listed/" target="_blank" rel="noopener">新三板在线 - 中国最大的新三板生态平台</a>（各行各业的新三板上市公司财务数据，高管数据等）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.qichacha.com/" target="_blank" rel="noopener">企查查|企业查询</a>（查询企业的产品，品牌和法人信息）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.tianyancha.com/" target="_blank" rel="noopener">企业注册信息查询</a>（天眼查，同企查查）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.sec.gov/" target="_blank" rel="noopener">SEC.gov | Home</a>（美国上市公司年度财务报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.cninfo.com.cn/cninfo-new/disclosure/fund_listed" target="_blank" rel="noopener">巨潮资讯网—</a>（中国上市公司季度年度财务报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//ir.baidu.com/phoenix.zhtml%3Fc%3D188488%26p%3Dirol-irhome" target="_blank" rel="noopener">Baidu | Investors</a>（各大上市公司季度财报，IR.XX公司.com，比如百度这个）</li>
</ol>
<p><strong>六，投资机构的统计网站（创业方向选择，投融资选择的时候用）</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=https%3A//www.itjuzi.com/" target="_blank" rel="noopener">IT桔子 | IT互联网公司产品数据库及商业信息服务</a>（IT桔子，中国创业公司投融资数据和报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.evervc.com/" target="_blank" rel="noopener">天天投-专业高效的免费创业投融资服务平台！</a>（创业公司数据库）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//fellowplus.com/investors" target="_blank" rel="noopener">投资人列表 | FellowPlus</a>（投资人列表和支持数据库查询）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.chinaventure.com.cn/cmsmodel/report/list.shtml" target="_blank" rel="noopener">研究院_ChinaVenture投资中国网</a>-（投中的每个季度的行业融资报告，不定期有专项分析报告）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cbinsights.com/blog/" target="_blank" rel="noopener">CB Insights - Blog</a> （CBI insights的一系列产品，包括公司的估值，独角兽公司列表等）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cbinsights.com/research-downround-tracker" target="_blank" rel="noopener">The Downround Tracker</a>（公司估值下降的趋势）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cbinsights.com/research-unicorn-companies" target="_blank" rel="noopener">The Complete List of Unicorn Companies</a>（独角兽公司列表）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.renaissancecapital.com/ipohome/marketwatch.aspx" target="_blank" rel="noopener">IPO Center: IPO Market, IPO News, IPO Calendars, IPO Pricings, IPO Voting</a>（IPO相关新闻和趋势报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.privco.com/dashboard" target="_blank" rel="noopener">PrivCo | Private Company Financial Intelligence</a>（美国金融数据公司，主要关注未上市公司的所有投融资资料，目前涵盖的公司包括全世界，当然也包括中国公司）</li>
<li>券商<a href="https://link.zhihu.com/?target=http%3A//data.eastmoney.com/report/hyyb.html%23dHA9MCZjZz0wJmR0PTImaHk9NDQ3JnBhZ2U9MQ%3D%3D" target="_blank" rel="noopener">行业研究报告</a> （国内券商的行业报告，策略报告，可以筛选行业，筛选报告类型）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//pitchbook.com/news/reports" target="_blank" rel="noopener">https://pitchbook.com/news/reports</a>（PitchBook的PE,VC，M&amp;A行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.chinaventure.com.cn/cmsmodel/report/study/count/list.shtml" target="_blank" rel="noopener">研究院_ChinaVenture投资中国网</a> （IPO 投融资行业报告）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.dowjones.com/press-room/dow-jones-venturesource-2q16-u-s-venture-capital-report/" target="_blank" rel="noopener">Dow Jones VentureSource 2Q’16 U.S. Venture Capital Report</a>（道琼斯旗下机构Dow Jones LP Source行业投资报告）</li>
<li>NVCA <a href="https://link.zhihu.com/?target=http%3A//nvca.org/research/venture-investment/" target="_blank" rel="noopener">Venture Investment</a>（美国国家风险投资协会，每个季度和年度都会出投融资行业报告）</li>
<li>PWC-<a href="https://link.zhihu.com/?target=https%3A//www.pwcmoneytree.com/" target="_blank" rel="noopener">MoneyTree Home</a>（PWC的money tree report是每个季度美国的风险投资行业报告）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//home.kpmg.com/xx/en/home/insights.html" target="_blank" rel="noopener">https://home.kpmg.com/xx/en/home/insights.html</a> （KPMG毕马威的insights报告，一般是每个季度的创投趋势，比较细致的分析）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//mattermark.com//" target="_blank" rel="noopener">Mattermark - Discover, Enrich, &amp; Analyze Companies</a>（创业公司投资并购信息一站式搜索）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//pitchbook.com/" target="_blank" rel="noopener">M&amp;A, Private Equity &amp; Venture Capital Database</a>（创业公司投资并购信息一站式搜索）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.datafox.com/" target="_blank" rel="noopener">DataFox | Prospect Sales Leads with Company Signals</a>（创业公司投资并购信息一站式搜索）</li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.crunchbase.com/%23/home/index" target="_blank" rel="noopener">CrunchBase accelerates innovation by bringing together data on companies and the people behind them.</a>（创业公司数据库）</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.ventureintelligence.com/" target="_blank" rel="noopener">Venture Intelligence</a> PE/VC database</li>
<li><a href="https://link.zhihu.com/?target=http%3A//www.trefis.com/modeldemo/institutional/22340/Qpiyk/0700.HK%3FeasyAccessToken%3DPROVIDER_cf15b6285eebd7b94e7c2aa257b8c75161ce8a8c" target="_blank" rel="noopener">Tencent Holdings Ltd – Trefis</a>（各个公司的revenue model的预测和key driver的趋势，这个网站简直不能再棒）</li>
</ol>
<p><img src="https://pic4.zhimg.com/5d804a3a242cf5174f6679c148d180fb_b.jpg" alt="img"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://howgtd.com/2019/02/08/python-image-download/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="靑枫">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HowGTD">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/08/python-image-download/" itemprop="url">Scrapy实现图片下载</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-08T11:00:48+08:00">
                2019-02-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Scrapy-ImagesPipeline-图片下载"><a href="#Scrapy-ImagesPipeline-图片下载" class="headerlink" title="Scrapy_ImagesPipeline 图片下载"></a>Scrapy_ImagesPipeline 图片下载</h2><p>基于上次通过scrapy 实现<a href="https://www.howgtd.com/2019/02/01/python-spider/" target="_blank" rel="noopener">豆瓣电影top250的信息爬取</a>为基础，实现电影图片的下载；实现上主要基于scrapy 自带的ImagesPipeline，可以通过下面语句引入；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br></pre></td></tr></table></figure>
<h2 id="1、items-py-添加image-url字段"><a href="#1、items-py-添加image-url字段" class="headerlink" title="1、items.py 添加image_url字段"></a>1、items.py 添加image_url字段</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="comment"># 排序、名称、介绍、评星、评价</span></span><br><span class="line">    movie_num = scrapy.Field()</span><br><span class="line">    movie_name = scrapy.Field()</span><br><span class="line">    movie_introduce = scrapy.Field()</span><br><span class="line">    movie_star = scrapy.Field()</span><br><span class="line">    movie_eval = scrapy.Field()</span><br><span class="line">    movie_image_url = scrapy.Field()  <span class="comment">#主要增加了这一行</span></span><br></pre></td></tr></table></figure>
<h2 id="2、给pipeline-py-添加图片下载的类"><a href="#2、给pipeline-py-添加图片下载的类" class="headerlink" title="2、给pipeline.py 添加图片下载的类"></a>2、给pipeline.py 添加图片下载的类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">import</span> mysql.connector</span><br><span class="line"><span class="keyword">from</span> mysql.connector <span class="keyword">import</span> errorcode</span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> mysqlconfig</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="comment">#这里我们需要增加引入DropItem、ImagesPipeline、Request</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        cnx = cur = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cnx = mysql.connector.connect(**mysqlconfig)</span><br><span class="line">        <span class="keyword">except</span> mysql.connector.Error <span class="keyword">as</span> err:</span><br><span class="line">            <span class="keyword">if</span> err.errno == errorcode.ER_ACCESS_DENIED_ERROR:</span><br><span class="line">                print(<span class="string">'Something is wrong with your user name or password'</span>)</span><br><span class="line">            <span class="keyword">elif</span> err.errno == errorcode.ER_BAD_DB_ERROR:</span><br><span class="line">                print(<span class="string">"Database does not exist"</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(err)</span><br><span class="line">        <span class="comment"># item = dict(item)</span></span><br><span class="line">        sql = <span class="string">"insert into python_spider (movie_num,movie_name,movie_introduce,movie_star,movie_eval) values ('%s','%s','%s','%s','%s')"</span> % (</span><br><span class="line">            item[<span class="string">'movie_num'</span>], item[<span class="string">'movie_name'</span>], item[<span class="string">'movie_introduce'</span>], item[<span class="string">'movie_star'</span>], item[<span class="string">'movie_eval'</span>])</span><br><span class="line">        cur = cnx.cursor()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cur.execute(sql)</span><br><span class="line">            cnx.commit()</span><br><span class="line">            print(<span class="string">'insert into success'</span>)</span><br><span class="line">        <span class="keyword">except</span>  mysql.connector.Error <span class="keyword">as</span> err:</span><br><span class="line">            print(<span class="string">'insert into error'</span>)</span><br><span class="line">            <span class="keyword">print</span> item[<span class="string">'movie_num'</span>], item[<span class="string">'movie_name'</span>], item[<span class="string">'movie_introduce'</span>], item[<span class="string">'movie_star'</span>], item[<span class="string">'movie_eval'</span>]</span><br><span class="line">            <span class="keyword">print</span> err</span><br><span class="line">        cur.close()</span><br><span class="line">        cnx.close()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"><span class="comment">#增加ImageDown的类，1、需要集成ImagesPipeline；2、定义两个函数，get_media_requests：通过该函数实现图片资源的请求；同时定义item_completed，该函数将会得到get_media_requests的result，并进行本地存储；</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageDown</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"######我在下载"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        image_url = item[<span class="string">'movie_image_url'</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        <span class="comment"># 创建图片存储路径</span></span><br><span class="line">        path = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="comment"># 判断图片是否下载成功，若不成功则抛出DropItem提示</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> path:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">'Item contains no images'</span>)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'正在保存图片：'</span>, item[<span class="string">'movie_image_url'</span>]</span><br><span class="line">        <span class="keyword">print</span> <span class="string">u'主题'</span>, item[<span class="string">'movie_name'</span>]</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h2 id="3、在setting-py-配置图片下载信息"><a href="#3、在setting-py-配置图片下载信息" class="headerlink" title="3、在setting.py 配置图片下载信息"></a>3、在setting.py 配置图片下载信息</h2><p>主要修改配置项为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'doubanspider.pipelines.DoubanspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'doubanspider.pipelines.ImageDown'</span>: <span class="number">5</span>,  <span class="comment"># 后面的数字代表执行优先级 ，当执行pipeine的时候会按照数字由小到大执行</span></span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = <span class="string">'/Users/caizi/desktop/doubanimage'</span> <span class="comment">#图片存储目录</span></span><br></pre></td></tr></table></figure>
<p>需要将在pipeline.py新定义的ImageDown类在这里配置，该类才会被执行；IMAGES_STORE，我用的MAC，因此图片存储路径有些和windows有些不一样；</p>
<p>下面是完整的setting.py文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Scrapy settings for doubanspider project</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For simplicity, this file contains only settings considered important or</span></span><br><span class="line"><span class="comment"># commonly used. You can find more settings consulting the documentation:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     https://doc.scrapy.org/en/latest/topics/settings.html</span></span><br><span class="line"><span class="comment">#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line">BOT_NAME = <span class="string">'doubanspider'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'doubanspider.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'doubanspider.spiders'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS = 32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure a delay for requests for the same website (default: 0)</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay</span></span><br><span class="line"><span class="comment"># See also autothrottle settings and docs</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">0.5</span></span><br><span class="line"><span class="comment"># The download delay setting will honor only one of:</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_DOMAIN = 16</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_IP = 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable cookies (enabled by default)</span></span><br><span class="line"><span class="comment">#COOKIES_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable Telnet Console (enabled by default)</span></span><br><span class="line"><span class="comment">#TELNETCONSOLE_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line"><span class="comment">#DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',</span></span><br><span class="line"><span class="comment">#   'Accept-Language': 'en',</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable spider middlewares</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"><span class="comment">#SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    'doubanspider.middlewares.DoubanspiderSpiderMiddleware': 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'doubanspider.middlewares.DoubanspiderDownloaderMiddleware'</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable extensions</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/extensions.html</span></span><br><span class="line"><span class="comment">#EXTENSIONS = &#123;</span></span><br><span class="line"><span class="comment">#    'scrapy.extensions.telnet.TelnetConsole': None,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'doubanspider.pipelines.DoubanspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'doubanspider.pipelines.ImageDown'</span>: <span class="number">5</span>,  <span class="comment"># 后面的数字代表执行优先级 ，当执行pipeine的时候会按照数字由小到大执行</span></span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = <span class="string">'/Users/caizi/desktop/doubanimage'</span> <span class="comment">#图片存储目录</span></span><br><span class="line"><span class="comment"># Enable and configure the AutoThrottle extension (disabled by default)</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/autothrottle.html</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_ENABLED = True</span></span><br><span class="line"><span class="comment"># The initial download delay</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_START_DELAY = 5</span></span><br><span class="line"><span class="comment"># The maximum download delay to be set in case of high latencies</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_MAX_DELAY = 60</span></span><br><span class="line"><span class="comment"># The average number of requests Scrapy should be sending in parallel to</span></span><br><span class="line"><span class="comment"># each remote server</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span></span><br><span class="line"><span class="comment"># Enable showing throttling stats for every response received:</span></span><br><span class="line"><span class="comment">#AUTOTHROTTLE_DEBUG = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable and configure HTTP caching (disabled by default)</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span></span><br><span class="line"><span class="comment">#HTTPCACHE_ENABLED = True</span></span><br><span class="line"><span class="comment">#HTTPCACHE_EXPIRATION_SECS = 0</span></span><br><span class="line"><span class="comment">#HTTPCACHE_DIR = 'httpcache'</span></span><br><span class="line"><span class="comment">#HTTPCACHE_IGNORE_HTTP_CODES = []</span></span><br><span class="line"><span class="comment">#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改编码为utf-8</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#mysql config</span></span><br><span class="line">mysqlconfig = &#123;</span><br><span class="line">    <span class="string">'user'</span>: <span class="string">'root'</span>,</span><br><span class="line">    <span class="string">'password'</span>: <span class="string">'kk123456'</span>,</span><br><span class="line">    <span class="string">'host'</span>: <span class="string">'127.0.0.1'</span>,</span><br><span class="line">    <span class="string">'database'</span>: <span class="string">'python_demo'</span>,</span><br><span class="line">    <span class="string">'charset'</span> : <span class="string">'utf8'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4、运行main-py文件"><a href="#4、运行main-py文件" class="headerlink" title="4、运行main.py文件"></a>4、运行main.py文件</h2><p>运行后，就可以获得实现图片的下载了；</p>
<img src="/2019/02/08/python-image-download/douban_images.png" title="图片下载">
<blockquote>
<p>GitHub：<a href="https://github.com/zironglv/python-scrapy-dome" target="_blank" rel="noopener">https://github.com/zironglv/python-scrapy-dome</a></p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://howgtd.com/2019/02/01/python-spider/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="靑枫">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HowGTD">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/01/python-spider/" itemprop="url">Scrapy构建爬虫</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-01T15:29:28+08:00">
                2019-02-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="关于scrapy"><a href="#关于scrapy" class="headerlink" title="关于scrapy"></a>关于scrapy</h2><p>一个很成熟的爬虫框架，了解到的时候感觉很不错，学习数据抓取可以直接从这里开始学习；</p>
<img src="/2019/02/01/python-spider/scrapy.jpeg" title="scrapy">
<p>结构非常清晰，模块的实现的功能也比较明朗：</p>
<ul>
<li>scrapy engine 作为调度引擎起到协同4个模块，每个模块之间的交互都经过scrapy engine；</li>
<li>scheduler 是调度器的意思，负责处理需要爬取页面的队列调度；</li>
<li>downloader 负责从scheduler获取到需要爬取页面地址，并进行爬取；</li>
<li>spiders 负责定义数据需求，即需要那些数据，从downloader获取到页面的结果并对这类数据进行提取；同时起到探索的能力，发现有需要进一步爬取的页面url时，会将地址库返回给scheduler，等待排期后给到downloader；</li>
<li>item pipeline 是管道的意思，负责处理从spider获取到的数据进行对外输出存储；</li>
</ul>
<h2 id="环境安装与源码"><a href="#环境安装与源码" class="headerlink" title="环境安装与源码"></a>环境安装与源码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">环境：MAC</span><br><span class="line">使用IDE: pycharm <span class="number">2018</span></span><br><span class="line">python：<span class="number">2.7</span></span><br><span class="line">mysql：<span class="number">8.0</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>源码已经上传GitHub，如果环境类似，可以直接通过clone该仓库，里面涉及些包的引用和安装，新手比较荣容易跨过去；<a href="https://github.com/zironglv/python-scrapy-dome" target="_blank" rel="noopener">https://github.com/zironglv/python-scrapy-dome</a></p>
</blockquote>
<h2 id="开启爬虫之旅"><a href="#开启爬虫之旅" class="headerlink" title="开启爬虫之旅"></a>开启爬虫之旅</h2><h3 id="1、爬取目标分析"><a href="#1、爬取目标分析" class="headerlink" title="1、爬取目标分析"></a>1、爬取目标分析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">选取的目标是：https://movie.douban.com/top250</span><br><span class="line">尝试将250个电影排名的相关介绍爬取下来；</span><br></pre></td></tr></table></figure>
<h3 id="2、items-py建立爬取目标"><a href="#2、items-py建立爬取目标" class="headerlink" title="2、items.py建立爬取目标"></a>2、items.py建立爬取目标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="comment"># 排序、名称、介绍、评星、评价</span></span><br><span class="line">    movie_num = scrapy.Field()</span><br><span class="line">    movie_name = scrapy.Field()</span><br><span class="line">    movie_introduce = scrapy.Field()</span><br><span class="line">    movie_star = scrapy.Field()</span><br><span class="line">    movie_eval = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>我们可以按照这个类定义的样式，将需要获取的字段变量配置好便可；</p>
<blockquote>
<p>使用chrome，可以安装xpath helper小工具，方便写xpath定位内容</p>
</blockquote>
<h3 id="3、通过xpath提取字段"><a href="#3、通过xpath提取字段" class="headerlink" title="3、通过xpath提取字段"></a>3、通过xpath提取字段</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> doubanspider.items <span class="keyword">import</span> DoubanspiderItem   <span class="comment">#引入开头配置items类</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpiderSpider</span><span class="params">(scrapy.Spider)</span>:</span>           </span><br><span class="line">    name = <span class="string">'douban_spider'</span></span><br><span class="line">    allowed_domains = [<span class="string">'movie.douban.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://movie.douban.com/top250'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span>     <span class="comment">#根据网页字段采用xpath进行字段提取</span></span><br><span class="line">        movie_list = response.xpath(<span class="string">"//ol[@class='grid_view']/li"</span>)</span><br><span class="line">        <span class="keyword">for</span> i_item <span class="keyword">in</span> movie_list:</span><br><span class="line">            douban_item = DoubanspiderItem()</span><br><span class="line">            douban_item[<span class="string">'movie_num'</span>] = i_item.xpath(<span class="string">".//div[@class='item']//em/text()"</span>).extract_first()</span><br><span class="line">            douban_item[<span class="string">'movie_name'</span>] = i_item.xpath(<span class="string">".//div[@class='hd']/a/span[1]/text()"</span>).extract_first()</span><br><span class="line">            content_list = i_item.xpath(<span class="string">".//div[@class='info']/div[@class='bd']/p/text()"</span>).extract()</span><br><span class="line">            <span class="keyword">for</span> content_i <span class="keyword">in</span> content_list :</span><br><span class="line">                content_s = <span class="string">""</span>.join(content_i.split())</span><br><span class="line">                douban_item[<span class="string">'movie_introduce'</span>] = content_s</span><br><span class="line">            douban_item[<span class="string">'movie_star'</span>] = i_item.xpath(<span class="string">".//div[@class='item']//span[@class='rating_num']/text()"</span>).extract_first()</span><br><span class="line">            douban_item[<span class="string">'movie_eval'</span>] = i_item.xpath(<span class="string">".//div[@class='item']//div[@class='star']/span[4]/text()"</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> douban_item    <span class="comment">#将派去内容通过yield提交给items.pipeline</span></span><br><span class="line">        next_link = response.xpath(<span class="string">"//span[@class='next']/link/@href"</span>).extract()</span><br><span class="line">        <span class="keyword">if</span> next_link :</span><br><span class="line">            next_link = next_link[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(<span class="string">"https://movie.douban.com/top250"</span>+next_link,callback=self.parse)</span><br></pre></td></tr></table></figure>
<h3 id="4、pipeline存储数据"><a href="#4、pipeline存储数据" class="headerlink" title="4、pipeline存储数据"></a>4、pipeline存储数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> mysql.connector</span><br><span class="line"><span class="keyword">from</span> mysql.connector <span class="keyword">import</span> errorcode</span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> mysqlconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        cnx = cur = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cnx = mysql.connector.connect(**mysqlconfig)</span><br><span class="line">        <span class="keyword">except</span> mysql.connector.Error <span class="keyword">as</span> err:</span><br><span class="line">            <span class="keyword">if</span> err.errno == errorcode.ER_ACCESS_DENIED_ERROR:</span><br><span class="line">                print(<span class="string">'Something is wrong with your user name or password'</span>)</span><br><span class="line">            <span class="keyword">elif</span> err.errno == errorcode.ER_BAD_DB_ERROR:</span><br><span class="line">                print(<span class="string">"Database does not exist"</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(err)</span><br><span class="line">       <span class="comment"># item = dict(item)</span></span><br><span class="line">        sql = <span class="string">"insert into python_spider (movie_num,movie_name,movie_introduce,movie_star,movie_eval) values ('%s','%s','%s','%s','%s')"</span> %(item[<span class="string">'movie_num'</span>],item[<span class="string">'movie_name'</span>],item[<span class="string">'movie_introduce'</span>],item[<span class="string">'movie_star'</span>],item[<span class="string">'movie_eval'</span>])</span><br><span class="line">        cur = cnx.cursor()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cur.execute(sql)</span><br><span class="line">            cnx.commit()</span><br><span class="line">            print(<span class="string">'insert into success'</span>)</span><br><span class="line">        <span class="keyword">except</span>  mysql.connector.Error <span class="keyword">as</span> err:</span><br><span class="line">            print(<span class="string">'insert into error'</span>)</span><br><span class="line">            <span class="keyword">print</span> item[<span class="string">'movie_num'</span>],item[<span class="string">'movie_name'</span>],item[<span class="string">'movie_introduce'</span>],item[<span class="string">'movie_star'</span>],item[<span class="string">'movie_eval'</span>]</span><br><span class="line">            <span class="keyword">print</span> err</span><br><span class="line">        cur.close()</span><br><span class="line">        cnx.close()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>通过引入mysql.connector，来建立mysql的链接，将数据写入到mysql；存储到mysql的过程比较复杂，我后面单独一篇来写；</p>
<h3 id="5、建立main-py来执行爬虫程序"><a href="#5、建立main-py来执行爬虫程序" class="headerlink" title="5、建立main.py来执行爬虫程序"></a>5、建立main.py来执行爬虫程序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl douban_spider'</span>.split())</span><br></pre></td></tr></table></figure>
<p>这样一个基于scrapy的小爬虫就搞定了；</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://howgtd.com/2019/01/31/why-learn-py/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="靑枫">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HowGTD">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/31/why-learn-py/" itemprop="url">初见-立个Flag</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-31T22:35:22+08:00">
                2019-01-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="初见"><a href="#初见" class="headerlink" title="初见"></a>初见</h2><p>刚刚弄好博客，用的hexo+github弄的，主要希望通过对更贴近代码的方式，来更好地立即产品以及产品内部逻辑。另外目前数据挖掘与分析越来越重要，作为一个互联网产品经理，对数据的理解也不应该停留在简单对汇总数据的分析，还需要尝试掌握一些更深度的数据挖掘，找到更细颗粒度的数据间联系，获取对业务的更深刻理解。</p>
<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>我初步捋了一下，python有比较成熟的架包，在数据爬取、数据清洗、数据分析上都比较不错，而且初步看了一下python的语法，还是比较好理解；趁这次假期，立个flag：构建爬虫，并能够学会几个比较成熟的数据分析包；</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">靑枫</p>
              <p class="site-description motion-element" itemprop="description">怎么更高效的把事情做好</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">靑枫</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
